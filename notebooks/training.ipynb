{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "\n",
    "from monet_boys.utils import set_distributed_training_strategy, discriminator_loss, generator_loss, calc_cycle_loss, identity_loss\n",
    "from monet_boys.cyclegan import CycleGan\n",
    "from monet_boys.generator import Generator\n",
    "from monet_boys.discriminator import Discriminator\n",
    "from monet_boys.data import load_dataset, read_tfrecord, decode_image\n",
    "\n",
    "# Load data\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "IMAGE_SIZE = [256, 256]\n",
    "\n",
    "GCS_PATH = 'raw_data'\n",
    "\n",
    "MONET_FILENAMES = tf.io.gfile.glob(str(GCS_PATH +'/monet_tfrec/*.tfrec'))\n",
    "PHOTO_FILENAMES = tf.io.gfile.glob(str(GCS_PATH +'/photo_tfrec/*.tfrec'))\n",
    "\n",
    "def decode_image(image):\n",
    "    '''All the images for the competition are already sized to 256x256. As these images are RGB images, set the channel to 3.\n",
    "    Additionally, we need to scale the images to a [-1, 1] scale'''\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    #print(image.shape)\n",
    "    image = (tf.cast(image, tf.float32) / 127.5) - 1\n",
    "    #print(image.shape)\n",
    "    image = tf.reshape(image, [*IMAGE_SIZE, 3])\n",
    "    #print(image.shape)\n",
    "    print('decode_image')\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def read_tfrecord(example):\n",
    "    '''Because we are building a generative model,\n",
    "    we don't need the labels or the image id so we'll only return the image\n",
    "    from the TFRecord.'''\n",
    "\n",
    "    tfrecord_format = {\n",
    "        \"image_name\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"target\": tf.io.FixedLenFeature([], tf.string)\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, tfrecord_format)\n",
    "    image = decode_image(example['image'])\n",
    "    print('read_tfrecord')\n",
    "    return image\n",
    "\n",
    "\n",
    "def load_dataset(filenames):\n",
    "    '''Define a function to extract the image from the files.'''\n",
    "    dataset = tf.data.TFRecordDataset(filenames)\n",
    "    dataset = dataset.map(read_tfrecord)\n",
    "    print('load_dataset')\n",
    "    return dataset\n",
    "\n",
    "\n",
    "monet_ds = load_dataset(MONET_FILENAMES).batch(1)\n",
    "photo_ds = load_dataset(PHOTO_FILENAMES).batch(1)\n",
    "\n",
    "final_ds = tf.data.Dataset.zip((monet_ds, photo_ds))\n",
    "\n",
    "print(type(final_ds))\n",
    "\n",
    "print(monet_ds.__dict__)\n",
    "\n",
    "\n",
    "# Set up strategy to TPU if possible\n",
    "print('Step 2 strategy')\n",
    "\n",
    "strategy = set_distributed_training_strategy()\n",
    "\n",
    "with strategy.scope():\n",
    "    print('Step 3 generators and discrim')\n",
    "\n",
    "    # Define generator and discriminators\n",
    "    monet_generator = Generator() # transforms photos to Monet-esque paintings\n",
    "    photo_generator = Generator() # transforms Monet paintings to be more like photos\n",
    "\n",
    "    monet_discriminator = Discriminator() # differentiates real Monet paintings and generated Monet paintings\n",
    "    photo_discriminator = Discriminator() # differentiates real photos and generated photos\n",
    "\n",
    "    # Select optimizers\n",
    "    monet_generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "    photo_generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "\n",
    "    monet_discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "    photo_discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "\n",
    "    #Instantiate model\n",
    "    cycle_gan_model = CycleGan(\n",
    "        monet_generator, photo_generator, monet_discriminator, photo_discriminator\n",
    "    )\n",
    "\n",
    "    cycle_gan_model.compile(\n",
    "        m_gen_optimizer = monet_generator_optimizer,\n",
    "        p_gen_optimizer = photo_generator_optimizer,\n",
    "        m_disc_optimizer = monet_discriminator_optimizer,\n",
    "        p_disc_optimizer = photo_discriminator_optimizer,\n",
    "        gen_loss_fn = generator_loss,\n",
    "        disc_loss_fn = discriminator_loss,\n",
    "        cycle_loss_fn = calc_cycle_loss,\n",
    "        identity_loss_fn = identity_loss\n",
    "    )\n",
    "\n",
    "    cycle_gan_model.fit(\n",
    "    tf.data.Dataset.zip((monet_ds, photo_ds)),\n",
    "    epochs=1\n",
    "    )\n",
    "\n",
    "    cycle_gan_model.save('my_model.h5')\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}